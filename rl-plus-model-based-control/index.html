<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> RL + Model-based Control: Using On-demand Optimal Control to Learn Versatile Legged Locomotion | DONGHO KANG </title> <meta name="author" content="Dongho Kang"> <meta name="description" content="IEEE Robotics and Automation Letters (RA-L)"> <meta name="keywords" content="legged robotics, character animation, optimal control, reinforcement learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.jpg?909542379a1154441a25b9a7e8ca0a7b"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://donghok.me/rl-plus-model-based-control/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "RL + Model-based Control: Using On-demand Optimal Control to Learn Versatile Legged Locomotion",
            "description": "IEEE Robotics and Automation Letters (RA-L)",
            "published": "May 27, 2023",
            "authors": [
              
              {
                "author": "Dongho Kang",
                "authorURL": "https://donghok.me/",
                "affiliations": [
                  {
                    "name": "CRL<d-footnote>Computational Robotics Lab.</d-footnote>, ETH Zurich",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Jin Cheng",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "CRL, ETH Zurich",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Miguel Zamora",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "CRL, ETH Zurich",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Fatemeh Zargarbashi",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "CRL, ETH Zurich",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Stelian Coros",
                "authorURL": "http://crl.ethz.ch/",
                "affiliations": [
                  {
                    "name": "CRL, ETH Zurich",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> DONGHO KANG </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>RL + Model-based Control: Using On-demand Optimal Control to Learn Versatile Legged Locomotion</h1> <p>IEEE Robotics and Automation Letters (RA-L)</p> </d-title> <d-byline></d-byline> <d-article> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid" src="/assets/img/kang2023rl/kang2023rl.png" alt="" title="teaser"> </div> </div> <p><br></p> <h1 id="abstract">Abstract</h1> <p>This letter presents a control framework that combines model-based optimal control and reinforcement learning (RL) to achieve versatile and robust legged locomotion. Our approach enhances the RL training process by incorporating on-demand reference motions generated through finite-horizon optimal control, covering a broad range of velocities and gaits. These reference motions serve as targets for the RL policy to imitate, leading to the development of robust control policies that can be learned with reliability. Furthermore, by utilizing realistic simulation data that captures whole-body dynamics, RL effectively overcomes the inherent limitations in reference motions imposed by modeling simplifications. We validate the robustness and controllability of the RL training process within our framework through a series of experiments. In these experiments, our method showcases its capability to generalize reference motions and effectively handle more complex locomotion tasks that may pose challenges for the simplified model, thanks to RL’s flexibility. Additionally, our framework effortlessly supports the training of control policies for robots with diverse dimensions, eliminating the necessity for robot-specific adjustments in the reward function and hyperparameters.</p> <p><strong>Paper: [<a href="https://ieeexplore.ieee.org/document/10225268" rel="external nofollow noopener" target="_blank">IEEE Xplore</a>]</strong>   <strong>Open access: [<a href="https://arxiv.org/abs/2305.17842" rel="external nofollow noopener" target="_blank">ArXiv</a>]</strong></p> <hr> <h1 id="supplementary-video">Supplementary Video</h1> <div class="embed-responsive embed-responsive-16by9"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/HXwLXdOf79c" allowfullscreen=""></iframe> </div> <hr> <h1 id="presentation">Presentation</h1> <p>We are pleased to announce that our paper has been selected for presentation at <a href="https://2024.ieee-icra.org/" rel="external nofollow noopener" target="_blank">ICRA 2024 in Yokohama, Japan</a>. Please join us for our oral presentation in the “Legged Robot III” session on May 14th from 16:30 to 18:00, and for our poster presentation session earlier that day from 10:30 to 12:00. We are excited to share our work with you and look forward to seeing you there.</p> <div class="embed-responsive embed-responsive-16by9"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/U4tCgsEFJmM" allowfullscreen=""></iframe> </div> <hr> <h1 id="demos">Demos</h1> <div class="embed-responsive embed-responsive-16by9"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/PCT5f6xsASk" allowfullscreen=""></iframe> </div> <p><br></p> <div class="embed-responsive embed-responsive-16by9"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/30CmkKIJ2fQ" allowfullscreen=""></iframe> </div> <p><br></p> <div class="embed-responsive embed-responsive-16by9"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/-tUdeYsNvSQ" allowfullscreen=""></iframe> </div> <hr> <h1 id="bibtex">Bibtex</h1> <figure class="highlight"><pre><code class="language-txt" data-lang="txt">@article{kang2023rl,
  author={Kang, Dongho and Cheng, Jin and Zamora, Miguel and Zargarbashi, Fatemeh and Coros, Stelian},
  journal={IEEE Robotics and Automation Letters}, 
  title={RL + Model-Based Control: Using On-Demand Optimal Control to Learn Versatile Legged Locomotion}, 
  year={2023},
  volume={8},
  number={10},
  pages={6619-6626},
  doi={10.1109/LRA.2023.3307008}
}</code></pre></figure> <hr> <h1 id="acknowledgment">Acknowledgment</h1> <p>This work has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement No. 866480.)</p> <p>We express our gratitude to Zijun Hui for his assistance with the robot experiments.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Dongho Kang. Last updated: July 08, 2025. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>